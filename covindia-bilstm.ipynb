{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/twitterdata/finalSentimentdata2.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sentiment_df = pd.read_csv('/kaggle/input/twitterdata/finalSentimentdata2.csv')\n\nfrom string import punctuation\nfrom nltk.corpus import stopwords\nprint(stopwords.words('english')[10:15])\n\ndef punctuation_stopwords_removal(sms):\n    # filters charecter-by-charecter : ['h', 'e', 'e', 'l', 'o', 'o', ' ', 'm', 'y', ' ', 'n', 'a', 'm', 'e', ' ', 'i', 's', ' ', 'p', 'u', 'r', 'v', 'a']\n    remove_punctuation = [ch for ch in sms if ch not in punctuation]\n    # convert them back to sentences and split into words\n    remove_punctuation = \"\".join(remove_punctuation).split()\n    filtered_sms = [word.lower() for word in remove_punctuation if word.lower() not in stopwords.words('english')]\n    return filtered_sms\n\nsentiment_df.loc[:, 'text'] = sentiment_df['text'].apply(punctuation_stopwords_removal)\n\nreviews_split = []\nfor i, j in sentiment_df.iterrows():\n    reviews_split.append(j['text'])\n    \nwords = []\nfor review in reviews_split:\n    for word in review:\n        words.append(word)\n        \n        \nfrom collections import Counter\n\ncounts = Counter(words)\nvocab = sorted(counts, key=counts.get, reverse=True)\nvocab_to_int = {word:ii for ii, word in enumerate(vocab, 1)}\n\nencoded_reviews = []\nfor review in reviews_split:\n    encoded_reviews.append([vocab_to_int[word] for word in review])\n    \n    \nlabels_to_int = []\nfor i, j in sentiment_df.iterrows():\n    if j['sentiment']=='joy':\n        labels_to_int.append(1)\n    else:\n        labels_to_int.append(0)\n        \n    \nreviews_len = Counter([len(x) for x in encoded_reviews])\nprint(max(reviews_len))\n\nnon_zero_idx = [ii for ii, review in enumerate(encoded_reviews) if len(encoded_reviews)!=0]\nencoded_reviews = [encoded_reviews[ii] for ii in non_zero_idx]\nencoded_labels = np.array([labels_to_int[ii] for ii in non_zero_idx])\n\ndef pad_features(reviews_int, seq_length):\n    features = np.zeros((len(reviews_int), seq_length), dtype=int)\n    for i, row in enumerate(reviews_int):\n        if len(row)!=0:\n            features[i, -len(row):] = np.array(row)[:seq_length]\n    return features\n\nseq_length = 50\npadded_features= pad_features(encoded_reviews, seq_length)\nprint(padded_features[:2])\n\nsplit_frac = 0.8\nsplit_idx = int(len(padded_features)*split_frac)\n\ntraining_x, remaining_x = padded_features[:split_idx], padded_features[split_idx:]\ntraining_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n\ntest_idx = int(len(remaining_x)*0.5)\nval_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\nval_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# torch.from_numpy creates a tensor data from n-d array\ntrain_data = TensorDataset(torch.from_numpy(training_x), torch.from_numpy(training_y))\ntest_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\nvalid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n\nbatch_size = 1\n\ntrain_loader = DataLoader(train_data, batch_size=batch_size)\ntest_loader = DataLoader(test_data, batch_size=batch_size)\nvalid_loader = DataLoader(valid_data, batch_size=batch_size)\n\ngpu_available = torch.cuda.is_available\n\nif gpu_available:\n    print('Training on GPU')\nelse:\n    print('GPU not available')","execution_count":2,"outputs":[{"output_type":"stream","text":"[\"you've\", \"you'll\", \"you'd\", 'your', 'yours']\n48\n[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0  853  186   20 1079 1457 4429 2201  407 1240 1079\n    15  218  337  167  253  462  337  122  168 4430 4431  140   23  264\n    58  765    3    5  195 1079 2966  274]\n [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0   80 1755 4432 2967\n  4433   86  854 1080 2968 4434 4435    7]]\nTraining on GPU\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\n\nclass Bidirectional_LSTM(nn.Module):\n    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.2):\n        super(Bidirectional_LSTM, self).__init__()\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.hidden_dim = hidden_dim\n        \n        self.embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, bidirectional=True, batch_first=True)\n        \n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(hidden_dim, output_size)\n        self.sig = nn.Sigmoid()\n    \n    def forward(self, x, hidden):\n        # x : batch_size * seq_length * features\n        batch_size = x.size(0)\n        x = x.long()\n        embeds = self.embedding_layer(x)\n        lstm_out, hidden = self.lstm(embeds, hidden)\n        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n        out = self.dropout(lstm_out)\n        out = self.fc(out)\n        sig_out = self.sig(out)\n        \n        sig_out = sig_out.view(batch_size, -1)\n        sig_out = sig_out[:, -1]\n        \n        return sig_out, hidden\n    \n    def init_hidden(self, batch_size):\n        # initialize weights for lstm layer\n        weights = next(self.parameters()).data\n        \n        if gpu_available:\n            hidden = (weights.new(self.n_layers*2, batch_size, self.hidden_dim).zero_().cuda(),\n                     weights.new(self.n_layers*2, batch_size, self.hidden_dim).zero_().cuda())\n        else:\n            hidden = (weights.new(self.n_layers*2, batch_size, self.hidden_dim).zero_(),\n                     weights.new(self.n_layers*2, batch_size, self.hidden_dim).zero())\n        return hidden","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\noutput_size = 1 # either happy or sad\nembedding_dim = 100\nhidden_dim = 256\nn_layers = 2","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\noutput_size = 1 # either happy or sad\nembedding_dim = 100\nhidden_dim = 256\nn_layers = 2\n\nbilstm = Bidirectional_LSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\nprint(bilstm)\n\nlr = 0.001\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(bilstm.parameters(), lr=lr)\n\nepochs = 4\ncount = 0\nprint_every = 100\nclip = 5 \n\nprint(gpu_available)\n\nif gpu_available:\n    bilstm.cuda()\n\nbilstm.train()\n\nfor e in range(epochs):\n    # initialize lstm's hidden layer \n    h = bilstm.init_hidden(batch_size)\n    for inputs, labels in train_loader:\n        count += 1\n        if gpu_available:\n            inputs, labels = inputs.cuda(), labels.cuda()\n        h = tuple([each.data for each in h])\n        \n        # training process\n        bilstm.zero_grad()\n        outputs, h = bilstm(inputs, h)\n        loss = criterion(outputs.squeeze(), labels.float())\n        loss.backward()\n        nn.utils.clip_grad_norm(bilstm.parameters(), clip)\n        optimizer.step()\n        \n        # print average training losses\n        if count % print_every == 0:\n            val_h = bilstm.init_hidden(batch_size)\n            val_losses = []\n            bilstm.eval()\n            for inputs, labels in valid_loader:\n                val_h = tuple([each.data for each in val_h])\n                if gpu_available:\n                    inputs, labels = inputs.cuda(), labels.cuda()\n            outputs, val_h = bilstm(inputs, val_h)\n            val_loss = criterion(outputs.squeeze(), labels.float())\n            val_losses.append(val_loss.item())\n        \n            bilstm.train()\n            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n                  \"Step: {}...\".format(count),\n                  \"Loss: {:.6f}...\".format(loss.item()),\n                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))","execution_count":5,"outputs":[{"output_type":"stream","text":"Bidirectional_LSTM(\n  (embedding_layer): Embedding(10663, 100)\n  (lstm): LSTM(100, 256, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (fc): Linear(in_features=256, out_features=1, bias=True)\n  (sig): Sigmoid()\n)\n<function is_available at 0x7f146ce96a70>\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])) is deprecated. Please ensure they have the same size.\n  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n","name":"stderr"},{"output_type":"stream","text":"Epoch: 1/4... Step: 100... Loss: 0.156004... Val Loss: 0.609800\nEpoch: 1/4... Step: 200... Loss: 0.144728... Val Loss: 0.607139\nEpoch: 1/4... Step: 300... Loss: 0.128784... Val Loss: 0.423508\nEpoch: 1/4... Step: 400... Loss: 0.391397... Val Loss: 0.846301\nEpoch: 1/4... Step: 500... Loss: 0.803269... Val Loss: 1.064108\nEpoch: 1/4... Step: 600... Loss: 0.284620... Val Loss: 0.691613\nEpoch: 1/4... Step: 700... Loss: 1.164828... Val Loss: 0.744839\nEpoch: 1/4... Step: 800... Loss: 0.781231... Val Loss: 0.852890\nEpoch: 1/4... Step: 900... Loss: 0.820904... Val Loss: 0.385625\nEpoch: 1/4... Step: 1000... Loss: 0.076785... Val Loss: 0.187513\nEpoch: 1/4... Step: 1100... Loss: 0.143303... Val Loss: 0.184733\nEpoch: 1/4... Step: 1200... Loss: 1.606484... Val Loss: 0.222027\nEpoch: 1/4... Step: 1300... Loss: 0.106615... Val Loss: 0.170604\nEpoch: 1/4... Step: 1400... Loss: 0.087672... Val Loss: 0.154669\nEpoch: 1/4... Step: 1500... Loss: 0.503057... Val Loss: 0.482759\nEpoch: 1/4... Step: 1600... Loss: 0.446842... Val Loss: 0.561215\nEpoch: 1/4... Step: 1700... Loss: 2.878007... Val Loss: 0.161223\nEpoch: 1/4... Step: 1800... Loss: 0.070345... Val Loss: 0.246979\nEpoch: 1/4... Step: 1900... Loss: 0.057158... Val Loss: 0.213171\nEpoch: 1/4... Step: 2000... Loss: 0.162127... Val Loss: 0.153555\nEpoch: 1/4... Step: 2100... Loss: 0.075914... Val Loss: 0.527937\nEpoch: 1/4... Step: 2200... Loss: 0.299684... Val Loss: 0.575567\nEpoch: 1/4... Step: 2300... Loss: 0.782038... Val Loss: 0.819147\nEpoch: 1/4... Step: 2400... Loss: 0.023852... Val Loss: 0.112473\nEpoch: 2/4... Step: 2500... Loss: 0.611000... Val Loss: 0.160273\nEpoch: 2/4... Step: 2600... Loss: 0.092494... Val Loss: 0.206116\nEpoch: 2/4... Step: 2700... Loss: 1.778651... Val Loss: 0.363153\nEpoch: 2/4... Step: 2800... Loss: 0.074351... Val Loss: 0.341929\nEpoch: 2/4... Step: 2900... Loss: 0.021154... Val Loss: 0.777723\nEpoch: 2/4... Step: 3000... Loss: 0.034742... Val Loss: 1.147819\nEpoch: 2/4... Step: 3100... Loss: 0.748767... Val Loss: 0.429761\nEpoch: 2/4... Step: 3200... Loss: 0.010827... Val Loss: 1.397974\nEpoch: 2/4... Step: 3300... Loss: 0.363948... Val Loss: 0.352836\nEpoch: 2/4... Step: 3400... Loss: 4.406103... Val Loss: 0.074038\nEpoch: 2/4... Step: 3500... Loss: 0.856601... Val Loss: 0.061829\nEpoch: 2/4... Step: 3600... Loss: 0.616466... Val Loss: 0.156986\nEpoch: 2/4... Step: 3700... Loss: 0.147380... Val Loss: 0.988728\nEpoch: 2/4... Step: 3800... Loss: 0.149020... Val Loss: 0.658403\nEpoch: 2/4... Step: 3900... Loss: 0.015499... Val Loss: 0.233041\nEpoch: 2/4... Step: 4000... Loss: 4.264175... Val Loss: 0.068729\nEpoch: 2/4... Step: 4100... Loss: 0.207801... Val Loss: 0.168770\nEpoch: 2/4... Step: 4200... Loss: 0.038156... Val Loss: 0.190621\nEpoch: 2/4... Step: 4300... Loss: 0.032647... Val Loss: 0.026934\nEpoch: 2/4... Step: 4400... Loss: 0.012968... Val Loss: 0.170168\nEpoch: 2/4... Step: 4500... Loss: 0.099873... Val Loss: 0.300499\nEpoch: 2/4... Step: 4600... Loss: 3.803513... Val Loss: 0.237306\nEpoch: 2/4... Step: 4700... Loss: 0.015827... Val Loss: 0.667041\nEpoch: 2/4... Step: 4800... Loss: 0.217499... Val Loss: 0.457171\nEpoch: 2/4... Step: 4900... Loss: 0.008825... Val Loss: 0.526430\nEpoch: 3/4... Step: 5000... Loss: 0.004052... Val Loss: 0.399030\nEpoch: 3/4... Step: 5100... Loss: 0.075840... Val Loss: 0.476057\nEpoch: 3/4... Step: 5200... Loss: 0.006267... Val Loss: 0.140546\nEpoch: 3/4... Step: 5300... Loss: 0.002195... Val Loss: 0.192648\nEpoch: 3/4... Step: 5400... Loss: 0.005635... Val Loss: 0.472542\nEpoch: 3/4... Step: 5500... Loss: 1.881207... Val Loss: 0.477566\nEpoch: 3/4... Step: 5600... Loss: 0.139435... Val Loss: 0.375400\nEpoch: 3/4... Step: 5700... Loss: 0.001855... Val Loss: 0.008210\nEpoch: 3/4... Step: 5800... Loss: 0.013467... Val Loss: 0.049996\nEpoch: 3/4... Step: 5900... Loss: 0.004876... Val Loss: 0.073596\nEpoch: 3/4... Step: 6000... Loss: 0.098873... Val Loss: 0.061155\nEpoch: 3/4... Step: 6100... Loss: 0.008419... Val Loss: 0.136628\nEpoch: 3/4... Step: 6200... Loss: 0.007225... Val Loss: 0.019516\nEpoch: 3/4... Step: 6300... Loss: 0.154610... Val Loss: 0.140862\nEpoch: 3/4... Step: 6400... Loss: 0.072577... Val Loss: 0.174820\nEpoch: 3/4... Step: 6500... Loss: 0.042134... Val Loss: 0.407770\nEpoch: 3/4... Step: 6600... Loss: 0.002836... Val Loss: 0.878455\nEpoch: 3/4... Step: 6700... Loss: 0.144834... Val Loss: 0.070223\nEpoch: 3/4... Step: 6800... Loss: 1.485387... Val Loss: 0.122979\nEpoch: 3/4... Step: 6900... Loss: 0.010041... Val Loss: 0.040911\nEpoch: 3/4... Step: 7000... Loss: 2.354779... Val Loss: 0.013203\nEpoch: 3/4... Step: 7100... Loss: 0.002220... Val Loss: 0.208350\nEpoch: 3/4... Step: 7200... Loss: 0.020018... Val Loss: 0.030148\nEpoch: 3/4... Step: 7300... Loss: 0.001534... Val Loss: 0.102039\nEpoch: 3/4... Step: 7400... Loss: 0.049528... Val Loss: 0.884928\nEpoch: 4/4... Step: 7500... Loss: 0.002357... Val Loss: 0.254683\nEpoch: 4/4... Step: 7600... Loss: 0.001853... Val Loss: 0.180733\nEpoch: 4/4... Step: 7700... Loss: 0.023746... Val Loss: 0.249878\nEpoch: 4/4... Step: 7800... Loss: 0.000981... Val Loss: 0.376039\nEpoch: 4/4... Step: 7900... Loss: 0.008791... Val Loss: 1.566281\nEpoch: 4/4... Step: 8000... Loss: 0.000293... Val Loss: 1.192101\nEpoch: 4/4... Step: 8100... Loss: 0.000725... Val Loss: 1.199834\nEpoch: 4/4... Step: 8200... Loss: 0.218880... Val Loss: 1.375878\nEpoch: 4/4... Step: 8300... Loss: 0.005941... Val Loss: 0.411537\nEpoch: 4/4... Step: 8400... Loss: 0.002793... Val Loss: 0.966035\nEpoch: 4/4... Step: 8500... Loss: 1.149275... Val Loss: 1.830888\nEpoch: 4/4... Step: 8600... Loss: 0.027200... Val Loss: 0.400725\nEpoch: 4/4... Step: 8700... Loss: 0.002909... Val Loss: 0.427955\nEpoch: 4/4... Step: 8800... Loss: 0.020280... Val Loss: 1.891318\nEpoch: 4/4... Step: 8900... Loss: 0.000578... Val Loss: 2.068368\nEpoch: 4/4... Step: 9000... Loss: 0.009075... Val Loss: 1.722849\nEpoch: 4/4... Step: 9100... Loss: 0.001421... Val Loss: 2.816073\nEpoch: 4/4... Step: 9200... Loss: 0.006200... Val Loss: 2.091260\nEpoch: 4/4... Step: 9300... Loss: 0.009084... Val Loss: 1.589716\nEpoch: 4/4... Step: 9400... Loss: 0.001227... Val Loss: 2.503544\nEpoch: 4/4... Step: 9500... Loss: 0.000433... Val Loss: 1.912326\nEpoch: 4/4... Step: 9600... Loss: 0.005351... Val Loss: 1.942316\nEpoch: 4/4... Step: 9700... Loss: 0.020343... Val Loss: 1.533142\nEpoch: 4/4... Step: 9800... Loss: 0.037330... Val Loss: 3.072150\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_losses = []\nnum_correct = 0\n\nh = bilstm.init_hidden(batch_size)\nbilstm.eval()\n\nfor inputs, labels in test_loader:\n    h = tuple([each.data for each in h])\n    if gpu_available:\n        inputs, labels = inputs.cuda(), labels.cuda()\n    \n    outputs, h = bilstm(inputs, h)\n    test_loss = criterion(outputs.squeeze(), labels.float())\n    test_losses.append(test_loss.item())\n    pred = torch.round(outputs.squeeze())\n    correct_tensor = pred.eq(labels.float().view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not gpu_available else np.squeeze(correct_tensor.cpu().numpy())\n    num_correct += np.sum(correct)\n\n# printing average statistics\nprint(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n    \n# accuracy over all test data\ntest_acc = num_correct/len(test_loader.dataset)\nprint(\"Test accuracy: {:.3f}\".format(test_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}