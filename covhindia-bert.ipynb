{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":23,"outputs":[{"output_type":"stream","text":"/kaggle/input/twitterdata/finalSentimentdata2.csv\n/kaggle/input/bert-base-uncased/vocab.txt\n/kaggle/input/bert-base-uncased/pytorch_model.bin\n/kaggle/input/bert-base-uncased/config.json\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/twitterdata/finalSentimentdata2.csv')","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"   Unnamed: 0 sentiment                                               text\n0        3204       sad  agree the poor in india are treated badly thei...\n1        1431       joy  if only i could have spent the with this cutie...\n2         654       joy  will nature conservation remain a priority in ...\n3        2530       sad  coronavirus disappearing in italy show this to...\n4        2296       sad  uk records lowest daily virus death toll since...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>sentiment</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3204</td>\n      <td>sad</td>\n      <td>agree the poor in india are treated badly thei...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1431</td>\n      <td>joy</td>\n      <td>if only i could have spent the with this cutie...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>654</td>\n      <td>joy</td>\n      <td>will nature conservation remain a priority in ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2530</td>\n      <td>sad</td>\n      <td>coronavirus disappearing in italy show this to...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2296</td>\n      <td>sad</td>\n      <td>uk records lowest daily virus death toll since...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nimport re\nimport string\n\n\ndef clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text']=data['text'].apply(lambda x: clean_text(x))","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text']=data['text'].apply(lambda x: remove_emoji(x))","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_labels(sentiment):\n    if sentiment == 'joy':\n        return 1\n    else:\n        return 0","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['sentiment']=data['sentiment'].apply(lambda x: encode_labels(x))","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"   Unnamed: 0  sentiment                                               text\n0        3204          0  agree the poor in india are treated badly thei...\n1        1431          1  if only i could have spent the with this cutie...\n2         654          1  will nature conservation remain a priority in ...\n3        2530          0  coronavirus disappearing in italy show this to...\n4        2296          0  uk records lowest daily virus death toll since...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>sentiment</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3204</td>\n      <td>0</td>\n      <td>agree the poor in india are treated badly thei...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1431</td>\n      <td>1</td>\n      <td>if only i could have spent the with this cutie...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>654</td>\n      <td>1</td>\n      <td>will nature conservation remain a priority in ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2530</td>\n      <td>0</td>\n      <td>coronavirus disappearing in italy show this to...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2296</td>\n      <td>0</td>\n      <td>uk records lowest daily virus death toll since...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import transformers\nfrom transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\nfrom torch.utils.data import Dataset, DataLoader","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)","execution_count":35,"outputs":[{"output_type":"execute_result","execution_count":35,"data":{"text/plain":"<torch._C.Generator at 0x7f958b5f35d0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(device)","execution_count":37,"outputs":[{"output_type":"stream","text":"cuda:0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"BERT_UNCASED = '/kaggle/input/bert-base-uncased'","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(BERT_UNCASED)","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet = 'Please practice social distancing amidst the pandemic.'\ntokens = tokenizer.tokenize(tweet)\ntoken_ids = tokenizer.convert_tokens_to_ids(tokens)\nprint(f' Sentence: {tweet}')\nprint(f'   Tokens: {tokens}')\nprint(f'Token IDs: {token_ids}')","execution_count":40,"outputs":[{"output_type":"stream","text":" Sentence: Please practice social distancing amidst the pandemic.\n   Tokens: ['please', 'practice', 'social', 'di', '##stan', '##cing', 'amidst', 'the', 'pan', '##de', '##mic', '.']\nToken IDs: [3531, 3218, 2591, 4487, 12693, 6129, 17171, 1996, 6090, 3207, 7712, 1012]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoding = tokenizer.encode_plus(\ntweet,\nmax_length=32,\nadd_special_tokens=True,\nreturn_token_type_ids=False,\npad_to_max_length=True,\nreturn_attention_mask=True,\nreturn_tensors='pt')\n\nencoding.keys()","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"dict_keys(['input_ids', 'attention_mask'])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoding['input_ids'].flatten()","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"tensor([  101,  3531,  3218,  2591,  4487, 12693,  6129, 17171,  1996,  6090,\n         3207,  7712,  1012,   102,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoding['attention_mask'].flatten()","execution_count":48,"outputs":[{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"token_lengths=[]\nfor text in data.text:\n    token_lengths.append(len(tokenizer.encode(text, max_length=512)))\n\nprint(max(token_lengths))","execution_count":42,"outputs":[{"output_type":"stream","text":"92\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_LENGTH = 100","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Covid19Tweet(Dataset):\n    \n    def __init__(self, tweets, sentiment, tokenizer, max_len):\n        \n        \n        self.tweets = tweets\n        self.sentiment = sentiment\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n    def __len__(self):\n        return len(self.tweets)\n    def __getitem__(self, item):\n        \n        tweets = str(self.tweets[item])\n        sentiment = self.sentiment[item]\n        encoding = self.tokenizer.encode_plus(\n        tweets,\n        add_special_tokens=True,\n        max_length=self.max_len,\n        return_token_type_ids=False,\n        pad_to_max_length=True,\n        return_attention_mask=True,\n        return_tensors='pt')\n        return {\n        'tweet_text': tweets,\n         'input_ids': encoding['input_ids'].flatten(),\n         'attention_mask': encoding['attention_mask'].flatten(),\n         'sentiments': torch.tensor(sentiment, dtype=torch.long)\n          }","execution_count":100,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":102,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, val = train_test_split(\n  data,\n  test_size=0.1,\n  random_state=RANDOM_SEED\n)","execution_count":103,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, val.shape","execution_count":50,"outputs":[{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"((2472, 3), (618, 3))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_data_loader(data, tokenizer, max_len, batch_size):\n    \n    ds = Covid19Tweet(tweets=data.text.to_numpy(),\n    sentiment=data.sentiment.to_numpy(),\n    tokenizer=tokenizer,\n    max_len=max_len)\n    return DataLoader(\n    ds,\n    batch_size=batch_size,\n    num_workers=4)\n\n\nBATCH_SIZE = 32\ntrain_data_loader = create_data_loader(train, tokenizer, MAX_LENGTH, BATCH_SIZE)\nval_data_loader = create_data_loader(val, tokenizer, MAX_LENGTH, BATCH_SIZE)","execution_count":105,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = next(iter(train_data_loader))\ndf.keys()","execution_count":55,"outputs":[{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"dict_keys(['tweet', 'input_ids', 'attention_mask', 'sentiments'])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('tweet : ', df['tweet'][1])\nprint('input_ids : ', df['input_ids'][1])\nprint('attention_mask : ', df['attention_mask'][1])\nprint('sentiments : ', df['sentiments'][1])","execution_count":58,"outputs":[{"output_type":"stream","text":"tweet :  you forgot the third india one that is try their best to spread the last and the most important one forth india those protecting the ones spreading this disease\ninput_ids :  tensor([  101,  3531,  3218,  2591,  4487, 12693,  6129, 17171,  1996,  6090,\n         3207,  7712,  1012,   102,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0])\nattention_mask :  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0])\nsentiments :  tensor(0)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"bert_model = BertModel.from_pretrained(BERT_UNCASED)","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SentimentClassifier(nn.Module):\n    \n    def __init__(self, n_classes):\n        \n        super(SentimentClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n        self.drop = nn.Dropout(p=0.3)\n        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n    def forward(self, input_ids, attention_mask):\n        \n        _, pooled_output = self.bert(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n    )\n        output = self.drop(pooled_output)\n        return self.out(output)","execution_count":106,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_classes = 2 # positive, negative\nmodel = SentimentClassifier(n_classes)\nmodel = model.to(device)","execution_count":93,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_ids = df['input_ids'].to(device)\nattention_mask = df['attention_mask'].to(device)","execution_count":94,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn.functional as F\n\n\nF.softmax(model(input_ids, attention_mask), dim=1)","execution_count":95,"outputs":[{"output_type":"execute_result","execution_count":95,"data":{"text/plain":"tensor([[0.4931, 0.5069],\n        [0.3982, 0.6018],\n        [0.6037, 0.3963],\n        [0.5324, 0.4676],\n        [0.4075, 0.5925],\n        [0.4295, 0.5705],\n        [0.6103, 0.3897],\n        [0.4982, 0.5018],\n        [0.4552, 0.5448],\n        [0.6315, 0.3685],\n        [0.4313, 0.5687],\n        [0.5429, 0.4571],\n        [0.3773, 0.6227],\n        [0.4825, 0.5175],\n        [0.4351, 0.5649],\n        [0.5248, 0.4752],\n        [0.5042, 0.4958],\n        [0.4639, 0.5361],\n        [0.4922, 0.5078],\n        [0.4194, 0.5806],\n        [0.3633, 0.6367],\n        [0.4049, 0.5951],\n        [0.5927, 0.4073],\n        [0.4585, 0.5415],\n        [0.4017, 0.5983],\n        [0.4702, 0.5298],\n        [0.4054, 0.5946],\n        [0.4638, 0.5362],\n        [0.4530, 0.5470],\n        [0.5254, 0.4746],\n        [0.3918, 0.6082],\n        [0.3992, 0.6008]], device='cuda:0', grad_fn=<SoftmaxBackward>)"},"metadata":{}}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model.parameters","execution_count":66,"outputs":[{"output_type":"execute_result","execution_count":66,"data":{"text/plain":"<bound method Module.parameters of SentimentClassifier(\n  (bert_model): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (drop): Dropout(p=0.2, inplace=False)\n  (fc): Linear(in_features=768, out_features=2, bias=True)\n)>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 10\noptimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\ntotal_steps = len(train_data_loader) * EPOCHS\nscheduler = get_linear_schedule_with_warmup(\n  optimizer,\n  num_warmup_steps=0,\n  num_training_steps=total_steps\n)\nloss_fn = nn.CrossEntropyLoss().to(device)","execution_count":107,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_epoch(model,data_loader,loss_fn,optimizer,device,scheduler, n_examples):  \n    model = model.train()\n    losses = []\n    correct_predictions = 0\n    for d in data_loader:\n        \n        input_ids = d[\"input_ids\"].to(device)\n        attention_mask = d[\"attention_mask\"].to(device)\n        targets = d[\"sentiments\"].to(device)\n        outputs = model(input_ids=input_ids,attention_mask=attention_mask)\n        _, preds = torch.max(outputs, dim=1)\n        loss = loss_fn(outputs, targets)\n        correct_predictions += torch.sum(preds == targets)\n        losses.append(loss.item())\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n    return correct_predictions.double() / n_examples, np.mean(losses)","execution_count":108,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_model(model, data_loader, loss_fn, device, n_examples):\n    \n    model = model.eval()\n    losses = []\n    correct_predictions = 0\n    with torch.no_grad():\n        for d in data_loader:\n            input_ids = d[\"input_ids\"].to(device)\n            attention_mask = d[\"attention_mask\"].to(device)\n            targets = d[\"sentiments\"].to(device)\n            outputs = model(input_ids=input_ids,attention_mask=attention_mask)\n            _, preds = torch.max(outputs, dim=1)\n            loss = loss_fn(outputs, targets)\n            correct_predictions += torch.sum(preds == targets)\n            losses.append(loss.item())\n        return correct_predictions.double() / n_examples, np.mean(losses)\n            ","execution_count":109,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nhistory = defaultdict(list)\nbest_accuracy = 0\nfor epoch in range(EPOCHS):\n    print(f'Epoch {epoch + 1}/{EPOCHS}')\n    print('-' * 10)\n    train_acc, train_loss = train_epoch(model,train_data_loader,loss_fn,optimizer,device,scheduler,len(train))\n    print(f'Train loss {train_loss} accuracy {train_acc}')\n    val_acc, val_loss = eval_model(model,val_data_loader,loss_fn,device,len(val))\n    print(f'Val   loss {val_loss} accuracy {val_acc}')\n    print()\n    history['train_acc'].append(train_acc)\n    history['train_loss'].append(train_loss)\n    history['val_acc'].append(val_acc)\n    history['val_loss'].append(val_loss)\n    if val_acc > best_accuracy:\n        \n        torch.save(model.state_dict(), 'best_model_state.bin')\n        best_accuracy = val_acc","execution_count":110,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n----------\nTrain loss 0.4187071273724238 accuracy 0.823804386911183\nVal   loss 0.22082368060946464 accuracy 0.9158576051779935\n\nEpoch 2/10\n----------\nTrain loss 0.2161241812395981 accuracy 0.9241280115066522\nVal   loss 0.21779102105647324 accuracy 0.9288025889967638\n\nEpoch 3/10\n----------\nTrain loss 0.12591336070206657 accuracy 0.9661992089176555\nVal   loss 0.20893345195800067 accuracy 0.9449838187702266\n\nEpoch 4/10\n----------\nTrain loss 0.06210743753646297 accuracy 0.9859762675296656\nVal   loss 0.2355087656993419 accuracy 0.9449838187702266\n\nEpoch 5/10\n----------\nTrain loss 0.04543946995453416 accuracy 0.9906508450197771\nVal   loss 0.25116687421686945 accuracy 0.9449838187702266\n\nEpoch 6/10\n----------\nTrain loss 0.03228857728716885 accuracy 0.9938870909744696\nVal   loss 0.27514614432584494 accuracy 0.9385113268608415\n\nEpoch 7/10\n----------\nTrain loss 0.022422273702191554 accuracy 0.9960445882775979\nVal   loss 0.29156487630680206 accuracy 0.941747572815534\n\nEpoch 8/10\n----------\nTrain loss 0.020775052109979434 accuracy 0.9964041711614526\nVal   loss 0.3336008047335781 accuracy 0.9385113268608415\n\nEpoch 9/10\n----------\nTrain loss 0.018567628451976282 accuracy 0.9964041711614526\nVal   loss 0.3208996533532627 accuracy 0.9385113268608415\n\nEpoch 10/10\n----------\nTrain loss 0.016015937977374113 accuracy 0.9971233369291621\nVal   loss 0.3178609122056514 accuracy 0.9385113268608415\n\nCPU times: user 4min 41s, sys: 5.84 s, total: 4min 47s\nWall time: 5min 2s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sad_sample_tweet = 'It is very sad to see the corona pandemic increasing at such an alarming rate'","execution_count":115,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"happy_sample_tweet = 'It is amazing to see that New Zealand reaches 100 days without Covid transmission!'","execution_count":121,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_review = tokenizer.encode_plus(sad_sample_tweet,max_length=MAX_LENGTH,add_special_tokens=True,\n                                           return_token_type_ids=False,pad_to_max_length=True,return_attention_mask=True,\n                                           return_tensors='pt')","execution_count":116,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_happy_review = tokenizer.encode_plus(happy_sample_tweet,max_length=MAX_LENGTH,add_special_tokens=True,\n                                           return_token_type_ids=False,pad_to_max_length=True,return_attention_mask=True,\n                                           return_tensors='pt')","execution_count":122,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = ['sad', 'happy']\n\n\ninput_ids = encoded_review['input_ids'].to(device)\nattention_mask = encoded_review['attention_mask'].to(device)\noutput = model(input_ids, attention_mask)\n_, prediction = torch.max(output, dim=1)\nprint('Review text :{}'.format(sad_sample_tweet))\nprint('Sentiment :{}'.format(classes[prediction]))","execution_count":120,"outputs":[{"output_type":"stream","text":"Review text :It is very sad to see the corona pandemic increasing at such an alarming rate\nSentiment :sad\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_ids = encoded_happy_review['input_ids'].to(device)\nattention_mask = encoded_happy_review['attention_mask'].to(device)\noutput = model(input_ids, attention_mask)\n_, prediction = torch.max(output, dim=1)\nprint('Review text : {}'.format(happy_sample_tweet))\nprint('Sentiment : {}'.format(classes[prediction]))","execution_count":123,"outputs":[{"output_type":"stream","text":"Review text :It is amazing to see that New Zealand reaches 100 days without Covid transmission!\nSentiment :happy\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}