{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":5,"outputs":[{"output_type":"stream","text":"/kaggle/input/glovetwitter27b100dtxt/glove.twitter.27B.100d.txt\n/kaggle/input/twitterdata/finalSentimentdata2.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_df = pd.read_csv('/kaggle/input/twitterdata/finalSentimentdata2.csv')","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from string import punctuation\nfrom nltk.corpus import stopwords\nprint(stopwords.words('english')[10:15])\n\ndef punctuation_stopwords_removal(sms):\n    # filters charecter-by-charecter : ['h', 'e', 'e', 'l', 'o', 'o', ' ', 'm', 'y', ' ', 'n', 'a', 'm', 'e', ' ', 'i', 's', ' ', 'p', 'u', 'r', 'v', 'a']\n    remove_punctuation = [ch for ch in sms if ch not in punctuation]\n    # convert them back to sentences and split into words\n    remove_punctuation = \"\".join(remove_punctuation).split()\n    filtered_sms = [word.lower() for word in remove_punctuation if word.lower() not in stopwords.words('english')]\n    return filtered_sms","execution_count":7,"outputs":[{"output_type":"stream","text":"[\"you've\", \"you'll\", \"you'd\", 'your', 'yours']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_df.loc[:, 'text'] = sentiment_df['text'].apply(punctuation_stopwords_removal)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews_split = []\nfor i, j in sentiment_df.iterrows():\n    reviews_split.append(j['text'])","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words = []\nfor review in reviews_split:\n    for word in review:\n        words.append(word)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\n\ncounts = Counter(words)\nvocab = sorted(counts, key=counts.get, reverse=True)\nvocab_to_int = {word:ii for ii, word in enumerate(vocab, 1)}","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_reviews = []\nfor review in reviews_split:\n    encoded_reviews.append([vocab_to_int[word] for word in review])","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_to_int = []\nfor i, j in sentiment_df.iterrows():\n    if j['sentiment']=='joy':\n        labels_to_int.append(1)\n    else:\n        labels_to_int.append(0)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews_len = Counter([len(x) for x in encoded_reviews])\nprint(max(reviews_len))","execution_count":14,"outputs":[{"output_type":"stream","text":"48\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_zero_idx = [ii for ii, review in enumerate(encoded_reviews) if len(encoded_reviews)!=0]\nencoded_reviews = [encoded_reviews[ii] for ii in non_zero_idx]\nencoded_labels = np.array([labels_to_int[ii] for ii in non_zero_idx])","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pad_features(reviews_int, seq_length):\n    features = np.zeros((len(reviews_int), seq_length), dtype=int)\n    for i, row in enumerate(reviews_int):\n        if len(row)!=0:\n            features[i, -len(row):] = np.array(row)[:seq_length]\n    return features","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq_length = 50\npadded_features= pad_features(encoded_reviews, seq_length)\nprint(padded_features[:2])","execution_count":17,"outputs":[{"output_type":"stream","text":"[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0  853  186   20 1079 1457 4429 2201  407 1240 1079\n    15  218  337  167  253  462  337  122  168 4430 4431  140   23  264\n    58  765    3    5  195 1079 2966  274]\n [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0   80 1755 4432 2967\n  4433   86  854 1080 2968 4434 4435    7]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"split_frac = 0.8\nsplit_idx = int(len(padded_features)*split_frac)\n\ntraining_x, remaining_x = padded_features[:split_idx], padded_features[split_idx:]\ntraining_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n\ntest_idx = int(len(remaining_x)*0.5)\nval_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\nval_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# torch.from_numpy creates a tensor data from n-d array\ntrain_data = TensorDataset(torch.from_numpy(training_x), torch.from_numpy(training_y))\ntest_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\nvalid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n\nbatch_size = 1\n\ntrain_loader = DataLoader(train_data, batch_size=batch_size)\ntest_loader = DataLoader(test_data, batch_size=batch_size)\nvalid_loader = DataLoader(valid_data, batch_size=batch_size)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gpu_available = torch.cuda.is_available\n\nif gpu_available:\n    print('Training on GPU')\nelse:\n    print('GPU not available')","execution_count":21,"outputs":[{"output_type":"stream","text":"Training on GPU\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch.nn as nn\n\nclass Bidirectional_LSTM_with_GloVeTwitter_Embeddings(nn.Module):\n    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, embedding_matrix, drop_prob=0.2):\n        super(Bidirectional_LSTM_with_GloVeTwitter_Embeddings, self).__init__()\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.hidden_dim = hidden_dim\n        \n        self.embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n        self.embedding_layer.weight = nn.Parameter(embedding_matrix, requires_grad=False)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, bidirectional=True, batch_first=True)\n        \n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(hidden_dim, output_size)\n        self.sig = nn.Sigmoid()\n    \n    def forward(self, x, hidden):\n        # x : batch_size * seq_length * features\n        batch_size = x.size(0)\n        x = x.long()\n        embeds = self.embedding_layer(x)\n        lstm_out, hidden = self.lstm(embeds, hidden)\n        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n        out = self.dropout(lstm_out)\n        out = self.fc(out)\n        sig_out = self.sig(out)\n        \n        sig_out = sig_out.view(batch_size, -1)\n        sig_out = sig_out[:, -1]\n        \n        return sig_out, hidden\n    \n    def init_hidden(self, batch_size):\n        # initialize weights for lstm layer\n        weights = next(self.parameters()).data\n        \n        if gpu_available:\n            hidden = (weights.new(self.n_layers*2, batch_size, self.hidden_dim).zero_().cuda(),\n                     weights.new(self.n_layers*2, batch_size, self.hidden_dim).zero_().cuda())\n        else:\n            hidden = (weights.new(self.n_layers*2, batch_size, self.hidden_dim).zero_(),\n                     weights.new(self.n_layers*2, batch_size, self.hidden_dim).zero())\n        return hidden","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load fasttext embeddings\nimport codecs\n\nprint('loading word embeddings...')\nglovetwitter_embedding = {}\nf = codecs.open('/kaggle/input/glovetwitter27b100dtxt/glove.twitter.27B.100d.txt', encoding='utf-8')\nfor line in f:\n    values = line.rstrip().rsplit(' ')\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    glovetwitter_embedding[word] = coefs\nf.close()","execution_count":29,"outputs":[{"output_type":"stream","text":"loading word embeddings...\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tqdm\n\nnum_words=len(vocab_to_int)+1\nglove_twitter_embedding_matrix = np.zeros((num_words,100))\n\nfor word,i in (vocab_to_int.items()):\n    if i > num_words:\n        continue\n    \n    emb_vec=glovetwitter_embedding.get(word)\n    if emb_vec is not None:\n        glove_twitter_embedding_matrix[i]=emb_vec","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\noutput_size = 1 # either happy or sad\nembedding_dim = 100\nhidden_dim = 256\nn_layers = 2\n\nbilstm_with_glove_twitter_embeddings = Bidirectional_LSTM_with_GloVeTwitter_Embeddings(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, torch.Tensor(glove_twitter_embedding_matrix))\nbilstm_with_glove_twitter_embeddings.embedding_layer.weight.data = torch.Tensor(glove_twitter_embedding_matrix).cuda()\n\nprint(bilstm_with_glove_twitter_embeddings)\n\nlr = 0.001\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(bilstm_with_glove_twitter_embeddings.parameters(), lr=lr)\n\nepochs = 4\ncount = 0\nprint_every = 100\nclip = 5 \nif gpu_available:\n    bilstm_with_glove_twitter_embeddings.cuda()\n\nbilstm_with_glove_twitter_embeddings.train()\nfor e in range(epochs):\n    # initialize lstm's hidden layer \n    h = bilstm_with_glove_twitter_embeddings.init_hidden(batch_size)\n    for inputs, labels in train_loader:\n        count += 1\n        if gpu_available:\n            inputs, labels = inputs.cuda(), labels.cuda()\n        h = tuple([each.data for each in h])\n        \n        # training process\n        bilstm_with_glove_twitter_embeddings.zero_grad()\n        outputs, h = bilstm_with_glove_twitter_embeddings(inputs, h)\n        loss = criterion(outputs.squeeze(), labels.float())\n        loss.backward()\n        nn.utils.clip_grad_norm(bilstm_with_glove_twitter_embeddings.parameters(), clip)\n        optimizer.step()\n        \n        # print average training losses\n        if count % print_every == 0:\n            val_h = bilstm_with_glove_twitter_embeddings.init_hidden(batch_size)\n            val_losses = []\n            bilstm_with_glove_twitter_embeddings.eval()\n            for inputs, labels in valid_loader:\n                val_h = tuple([each.data for each in val_h])\n                if gpu_available:\n                    inputs, labels = inputs.cuda(), labels.cuda()\n            outputs, val_h = bilstm_with_glove_twitter_embeddings(inputs, val_h)\n            val_loss = criterion(outputs.squeeze(), labels.float())\n            val_losses.append(val_loss.item())\n        \n            bilstm_with_glove_twitter_embeddings.train()\n            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n                  \"Step: {}...\".format(count),\n                  \"Loss: {:.6f}...\".format(loss.item()),\n                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))","execution_count":31,"outputs":[{"output_type":"stream","text":"Bidirectional_LSTM_with_GloVeTwitter_Embeddings(\n  (embedding_layer): Embedding(10663, 100)\n  (lstm): LSTM(100, 256, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (fc): Linear(in_features=256, out_features=1, bias=True)\n  (sig): Sigmoid()\n)\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])) is deprecated. Please ensure they have the same size.\n  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:38: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n","name":"stderr"},{"output_type":"stream","text":"Epoch: 1/4... Step: 100... Loss: 0.109153... Val Loss: 0.212390\nEpoch: 1/4... Step: 200... Loss: 0.114740... Val Loss: 0.248327\nEpoch: 1/4... Step: 300... Loss: 0.156756... Val Loss: 0.293008\nEpoch: 1/4... Step: 400... Loss: 0.335014... Val Loss: 0.414086\nEpoch: 1/4... Step: 500... Loss: 1.063716... Val Loss: 0.467379\nEpoch: 1/4... Step: 600... Loss: 0.350736... Val Loss: 0.450590\nEpoch: 1/4... Step: 700... Loss: 1.694402... Val Loss: 0.556861\nEpoch: 1/4... Step: 800... Loss: 1.302303... Val Loss: 0.521525\nEpoch: 1/4... Step: 900... Loss: 0.884050... Val Loss: 0.600392\nEpoch: 1/4... Step: 1000... Loss: 0.047599... Val Loss: 0.491401\nEpoch: 1/4... Step: 1100... Loss: 0.028393... Val Loss: 0.468005\nEpoch: 1/4... Step: 1200... Loss: 2.365734... Val Loss: 0.400009\nEpoch: 1/4... Step: 1300... Loss: 0.360712... Val Loss: 0.439259\nEpoch: 1/4... Step: 1400... Loss: 0.265293... Val Loss: 0.492754\nEpoch: 1/4... Step: 1500... Loss: 1.960674... Val Loss: 0.313198\nEpoch: 1/4... Step: 1600... Loss: 0.734609... Val Loss: 0.738179\nEpoch: 1/4... Step: 1700... Loss: 1.022735... Val Loss: 0.574973\nEpoch: 1/4... Step: 1800... Loss: 0.002334... Val Loss: 0.139736\nEpoch: 1/4... Step: 1900... Loss: 0.011411... Val Loss: 0.183840\nEpoch: 1/4... Step: 2000... Loss: 0.692502... Val Loss: 0.202198\nEpoch: 1/4... Step: 2100... Loss: 0.078297... Val Loss: 0.272583\nEpoch: 1/4... Step: 2200... Loss: 0.074110... Val Loss: 0.266459\nEpoch: 1/4... Step: 2300... Loss: 1.828151... Val Loss: 0.206466\nEpoch: 1/4... Step: 2400... Loss: 0.013062... Val Loss: 0.185344\nEpoch: 2/4... Step: 2500... Loss: 0.319427... Val Loss: 0.061273\nEpoch: 2/4... Step: 2600... Loss: 0.015373... Val Loss: 0.086493\nEpoch: 2/4... Step: 2700... Loss: 0.817051... Val Loss: 0.073741\nEpoch: 2/4... Step: 2800... Loss: 0.242687... Val Loss: 0.074685\nEpoch: 2/4... Step: 2900... Loss: 0.127899... Val Loss: 0.123760\nEpoch: 2/4... Step: 3000... Loss: 0.004202... Val Loss: 0.067462\nEpoch: 2/4... Step: 3100... Loss: 1.135116... Val Loss: 0.064818\nEpoch: 2/4... Step: 3200... Loss: 0.081155... Val Loss: 0.112294\nEpoch: 2/4... Step: 3300... Loss: 0.503442... Val Loss: 0.177147\nEpoch: 2/4... Step: 3400... Loss: 2.721671... Val Loss: 0.118114\nEpoch: 2/4... Step: 3500... Loss: 0.213222... Val Loss: 0.133569\nEpoch: 2/4... Step: 3600... Loss: 0.690133... Val Loss: 0.106193\nEpoch: 2/4... Step: 3700... Loss: 0.012766... Val Loss: 0.060848\nEpoch: 2/4... Step: 3800... Loss: 0.024169... Val Loss: 0.096985\nEpoch: 2/4... Step: 3900... Loss: 0.084306... Val Loss: 0.126772\nEpoch: 2/4... Step: 4000... Loss: 0.937087... Val Loss: 0.055771\nEpoch: 2/4... Step: 4100... Loss: 2.574521... Val Loss: 0.087539\nEpoch: 2/4... Step: 4200... Loss: 0.033728... Val Loss: 0.073575\nEpoch: 2/4... Step: 4300... Loss: 0.008515... Val Loss: 0.025640\nEpoch: 2/4... Step: 4400... Loss: 0.008353... Val Loss: 0.072659\nEpoch: 2/4... Step: 4500... Loss: 0.013000... Val Loss: 0.057156\nEpoch: 2/4... Step: 4600... Loss: 1.110154... Val Loss: 0.083017\nEpoch: 2/4... Step: 4700... Loss: 0.025415... Val Loss: 0.066380\nEpoch: 2/4... Step: 4800... Loss: 0.156326... Val Loss: 0.043239\nEpoch: 2/4... Step: 4900... Loss: 0.022968... Val Loss: 0.028729\nEpoch: 3/4... Step: 5000... Loss: 0.003302... Val Loss: 0.025239\nEpoch: 3/4... Step: 5100... Loss: 0.127092... Val Loss: 0.029922\nEpoch: 3/4... Step: 5200... Loss: 0.014972... Val Loss: 0.026974\nEpoch: 3/4... Step: 5300... Loss: 0.008508... Val Loss: 0.029403\nEpoch: 3/4... Step: 5400... Loss: 0.007272... Val Loss: 0.016488\nEpoch: 3/4... Step: 5500... Loss: 2.126872... Val Loss: 0.023499\nEpoch: 3/4... Step: 5600... Loss: 3.105133... Val Loss: 0.014601\nEpoch: 3/4... Step: 5700... Loss: 0.010391... Val Loss: 0.029175\nEpoch: 3/4... Step: 5800... Loss: 0.025989... Val Loss: 0.025616\nEpoch: 3/4... Step: 5900... Loss: 0.003884... Val Loss: 0.015973\nEpoch: 3/4... Step: 6000... Loss: 0.171453... Val Loss: 0.115592\nEpoch: 3/4... Step: 6100... Loss: 0.041877... Val Loss: 0.056313\nEpoch: 3/4... Step: 6200... Loss: 0.010646... Val Loss: 0.021208\nEpoch: 3/4... Step: 6300... Loss: 0.005314... Val Loss: 0.017115\nEpoch: 3/4... Step: 6400... Loss: 0.196896... Val Loss: 0.043570\nEpoch: 3/4... Step: 6500... Loss: 0.339553... Val Loss: 0.015518\nEpoch: 3/4... Step: 6600... Loss: 0.004981... Val Loss: 0.013400\nEpoch: 3/4... Step: 6700... Loss: 0.109428... Val Loss: 0.024923\nEpoch: 3/4... Step: 6800... Loss: 0.230360... Val Loss: 0.017567\nEpoch: 3/4... Step: 6900... Loss: 0.015781... Val Loss: 0.020163\nEpoch: 3/4... Step: 7000... Loss: 0.085517... Val Loss: 0.025404\nEpoch: 3/4... Step: 7100... Loss: 0.014069... Val Loss: 0.024067\nEpoch: 3/4... Step: 7200... Loss: 0.010117... Val Loss: 0.019603\nEpoch: 3/4... Step: 7300... Loss: 0.007756... Val Loss: 0.019593\nEpoch: 3/4... Step: 7400... Loss: 0.018232... Val Loss: 0.017055\nEpoch: 4/4... Step: 7500... Loss: 0.015719... Val Loss: 0.017071\nEpoch: 4/4... Step: 7600... Loss: 0.010839... Val Loss: 0.013924\nEpoch: 4/4... Step: 7700... Loss: 0.083226... Val Loss: 0.026861\nEpoch: 4/4... Step: 7800... Loss: 0.007173... Val Loss: 0.013767\nEpoch: 4/4... Step: 7900... Loss: 0.004392... Val Loss: 0.020466\nEpoch: 4/4... Step: 8000... Loss: 0.011121... Val Loss: 0.029448\nEpoch: 4/4... Step: 8100... Loss: 0.008249... Val Loss: 0.035753\nEpoch: 4/4... Step: 8200... Loss: 0.306338... Val Loss: 0.037609\nEpoch: 4/4... Step: 8300... Loss: 0.015695... Val Loss: 0.032061\nEpoch: 4/4... Step: 8400... Loss: 0.003912... Val Loss: 0.013531\nEpoch: 4/4... Step: 8500... Loss: 2.378521... Val Loss: 0.263981\nEpoch: 4/4... Step: 8600... Loss: 1.003721... Val Loss: 0.020021\nEpoch: 4/4... Step: 8700... Loss: 0.004503... Val Loss: 0.013906\nEpoch: 4/4... Step: 8800... Loss: 0.014379... Val Loss: 0.009917\nEpoch: 4/4... Step: 8900... Loss: 0.002713... Val Loss: 0.011587\nEpoch: 4/4... Step: 9000... Loss: 0.077607... Val Loss: 0.023880\nEpoch: 4/4... Step: 9100... Loss: 0.120579... Val Loss: 0.022527\nEpoch: 4/4... Step: 9200... Loss: 0.083293... Val Loss: 0.017141\nEpoch: 4/4... Step: 9300... Loss: 0.168027... Val Loss: 0.024502\nEpoch: 4/4... Step: 9400... Loss: 0.016772... Val Loss: 0.018267\nEpoch: 4/4... Step: 9500... Loss: 0.142183... Val Loss: 0.043974\nEpoch: 4/4... Step: 9600... Loss: 0.025155... Val Loss: 0.029896\nEpoch: 4/4... Step: 9700... Loss: 0.104250... Val Loss: 0.020326\nEpoch: 4/4... Step: 9800... Loss: 0.010506... Val Loss: 0.013586\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_losses = []\nnum_correct = 0\n\nh = bilstm_with_glove_twitter_embeddings.init_hidden(batch_size)\nbilstm_with_glove_twitter_embeddings.eval()\n\nfor inputs, labels in test_loader:\n    h = tuple([each.data for each in h])\n    if gpu_available:\n        inputs, labels = inputs.cuda(), labels.cuda()\n    \n    outputs, h = bilstm_with_glove_twitter_embeddings(inputs, h)\n    test_loss = criterion(outputs.squeeze(), labels.float())\n    test_losses.append(test_loss.item())\n    pred = torch.round(outputs.squeeze())\n    correct_tensor = pred.eq(labels.float().view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not gpu_available else np.squeeze(correct_tensor.cpu().numpy())\n    num_correct += np.sum(correct)\n\n# printing average statistics\nprint(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n    \n# accuracy over all test data\ntest_acc = num_correct/len(test_loader.dataset)\nprint(\"Test accuracy: {:.3f}\".format(test_acc))","execution_count":32,"outputs":[{"output_type":"stream","text":"Test loss: 0.264\nTest accuracy: 0.922\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}